# PRD — Quorum Chrome Extension (Microsoft Agent Framework)

**Document Owner:** Surya Sunkari  
**Last Updated:** 2026-01-08  
**Status:** Draft (MVP-focused)

---

## 1. Overview

### 1.1 Product Summary
A Chrome extension that lets a user ask a question and receive a **consensus-based answer** generated by multiple independent AI agents. Instead of requiring unanimity, the system returns an answer once a configurable **agreement ratio** is reached (e.g., 0.67). The extension uses a **Flask backend** that orchestrates agents via **Microsoft Agent Framework** to support multiple model providers in the future.

### 1.2 Core Idea
- Spin up **N independent answer agents** in parallel.
- An **arbiter/aggregator agent** compares answers and computes agreement.
- If agreement ≥ user-set **ratio threshold**, return consensus answer.
- If not, agents perform **reconciliation rounds** (bounded) until threshold met or the system falls back to best-effort output.

### 1.3 Goals
- Produce **more reliable** answers by using multiple independent agents.
- Allow user customization:
  - Number of agents (N)
  - Agreement ratio threshold (R)
  - Model selection (MVP: OpenAI models)
  - User-supplied API key(s)
- Keep UX simple: ask a question, see answer + confidence + “agreement reached” badge.
- Make architecture extensible to other model providers later via Microsoft Agent Framework.

### 1.4 Non-Goals (MVP)
- No long-term cloud user accounts / login.
- No team sharing or multi-user collaboration.
- No web browsing / citations (unless added later).
- No on-device model execution.
- No complex agent tool-use (e.g., browsing, file access) beyond Q&A.

---

## 2. Users & Use Cases

### 2.1 Primary User
- A knowledge worker/student/engineer who wants a “second opinion” style answer, fast.

### 2.2 Key Use Cases
1. **Quick Q&A with reliability**
   - “Explain X in simple terms.”
2. **Sanity-check reasoning**
   - “Is this approach correct? Any issues?”
3. **Compare and converge**
   - “Give a recommendation; converge on a single best answer.”

### 2.3 User Stories
- As a user, I can set **N agents** so I can trade cost/latency for reliability.
- As a user, I can set an **agreement ratio** so I don’t need unanimity.
- As a user, I can paste my **OpenAI API key** so I can use my own billing.
- As a user, I can see how many agents agreed and how many rounds were used.

---

## 3. Product Requirements

### 3.1 Functional Requirements

#### FR1 — Ask a Question (Extension UI)
- Provide an input box, submit button, and optional “advanced settings” drawer.
- Display:
  - Final answer
  - Agreement status (e.g., “Consensus: 4/5 (80%)”)
  - Confidence indicator (derived from arbiter)
  - Optional “Show agent responses” toggle (MVP: on by default or off by default—choose one)

#### FR2 — Agent Orchestration (Backend)
- Backend endpoint: `POST /ask`
- Orchestrate:
  - **N answer agents** (independent) in parallel
  - **Arbiter agent** to cluster/compare answers and compute agreement ratio
  - **Reconciliation loop** if ratio not met
- Cap:
  - `max_rounds` (default 2 or 3)
  - `max_total_tokens` and/or per-call token budgets
- Return best-effort answer even if ratio not met.

#### FR3 — Agreement Ratio Logic
- Let user set:
  - `N` (integer range)
  - `R` (0.50–1.00)
- Define agreement:
  - Arbiter clusters answers into “equivalent” groups (semantic equivalence, not string match).
  - Agreement ratio = (size of largest cluster) / N
- Success if agreement ratio ≥ R.

#### FR4 — Settings Management (User Customization)
- Settings stored locally in the extension (Chrome storage) and optionally mirrored to backend per request.
- Configurable fields:
  - Number of agents (N)
  - Agreement ratio (R)
  - Model (default OpenAI model)
  - API key(s)
  - Max reconciliation rounds
  - “Show agent outputs” toggle
- Provide “Reset to defaults.”

#### FR5 — API Key Handling
- User can enter an API key in extension settings.
- Key is stored in Chrome extension storage.
- On each request, extension sends key to backend over HTTPS (or backend uses a session token—see Security).
- Backend never logs the raw key; key is used only to authenticate provider calls.
- Provide “Test key” button.

#### FR6 — Provider Abstraction (Microsoft Agent Framework)
- Use Microsoft Agent Framework to define:
  - Answer agents
  - Arbiter agent
- Provider/model is configured via adapter layer so additional providers can be added later.

#### FR7 — Telemetry & Debug (MVP-light)
- Provide an optional debug view:
  - agent outputs (redacted if needed)
  - clusters / arbiter rationale (short)
  - number of rounds
- Default telemetry off; local debug only.

---

## 4. UX Requirements

### 4.1 Extension Surface
- Popup UI (primary):
  - Prompt input
  - Submit
  - Result panel
- Optional side panel (future):
  - persistent chat history

### 4.2 States
- Idle → Submitting → Streaming/Waiting → Result → Error
- Errors:
  - Missing/invalid API key
  - Backend unreachable
  - Rate-limited
  - Provider error

### 4.3 Success Indicators
- “Consensus Reached” badge when ratio met
- “Best Effort” badge when ratio not met (include achieved ratio)

---

## 5. System Design

### 5.1 High-Level Architecture
- **Chrome Extension (MV3)**
  - Popup UI (React/Vite or vanilla)
  - Background service worker
  - Chrome storage for settings
- **Flask Backend**
  - `/ask` orchestrator
  - Uses **Microsoft Agent Framework** for multi-agent workflow
  - Calls OpenAI models (MVP) via provider adapter

### 5.2 Key Components

#### A) AnswerAgent (xN)
- Role: independently answer the user question
- Output: strict structured JSON
  - `answer`
  - `confidence` (0–1)
  - `assumptions` (array)
  - `short_rationale` (<= 2–3 sentences)

#### B) ArbiterAgent
- Role:
  - normalize answers
  - determine equivalence clusters
  - choose best cluster
  - compute agreement ratio
  - produce consensus answer
- Output JSON:
  - `status`: `consensus_reached` | `needs_reconcile` | `best_effort`
  - `agreement_ratio`
  - `winning_cluster_size`
  - `consensus_answer`
  - `disagreement_summary`
  - `reconcile_instructions` (if needs reconcile)

#### C) Reconciliation Round (bounded loop)
- If ratio not met:
  - Send agents:
    - arbiter’s disagreement summary
    - winning answer cluster
    - instructions to reconcile
  - Agents respond with updated structured JSON.
  - Arbiter recomputes ratio.
- Stop if:
  - ratio met OR max_rounds reached.

### 5.3 API Contract

#### `POST /ask`
Request JSON:
```json
{
  "question": "string",
  "n_agents": 5,
  "agreement_ratio": 0.8,
  "max_rounds": 2,
  "model": "openai:<model-id>",
  "api_key": "user_key_string",
  "return_agent_outputs": true
}
```

Response JSON:
```json
{
  "status": "consensus_reached",
  "answer": "string",
  "agreement_ratio_achieved": 0.67,
  "agreement_threshold": 0.67,
  "winning_cluster_size": 2,
  "n_agents": 3,
  "rounds_used": 1,
  "confidence": 0.74,
  "disagreement_summary": "",
  "agent_outputs": []
}
```

## 6. Defaults, Limits, and Validation

### 6.1 Defaults

- N = 3
- R = 0.67
- max_rounds = 2
- return_agent_outputs = OFF

### 6.2 Validation

- N: integer 1–10 (MVP)
- R: float 0.0–1.0 (no min)
- max_rounds: integer 0–5

If N=1:
- agreement ratio achieved = 1.0
- consensus trivially reached if R ≤ 1.0

### 6.3 Cost/Latency Guardrails

Hard caps (server-side enforced):
- max N, max rounds, max tokens per agent

If user sets extremely low R (e.g., 0.0):
- The system can return immediately after first arbiter pass (still runs agents unless an optimization is added)
- Optional optimization: early stop if R=0.0 → skip reconciliation and return winning cluster from first round.

## 7. Security & Privacy

### 7.1 API Keys

- Stored locally in Chrome storage (masked in UI).
- Sent only over HTTPS to backend.
- Backend:
  - must not persist keys
  - must not log keys
  - should redact sensitive values in errors

### 7.2 Data Retention

- By default, do not store prompts/answers server-side.
- Optional future:
  - local "history" in extension only

## 8. Observability & Debug

### 8.1 Debug Mode (User-facing)

Toggle to show:
- per-agent answers
- cluster sizes
- rounds used
- achieved ratio

### 8.2 Backend Tracing

Use Microsoft Agent Framework tracing hooks for:
- call timings
- errors
- round counts

No sensitive data logging (keys, secrets).

## 9. Performance Targets (MVP)

- N=3, rounds ≤ 1:
  - Typical response under ~10s (provider-dependent)
- N=5, rounds ≤ 2:
  - Typical response under ~20–30s
- UI must remain responsive (loading states, no blocking).

## 10. Edge Cases & Fallback Behavior

- If ratio not met after max rounds:
  - Return best_effort:
    - winning cluster answer
    - achieved ratio
    - short disagreement summary
- Provider errors / rate limits:
  - bounded retries + clear error message
- Incoherent answers:
  - arbiter flags low confidence and returns cautious output

## 11. Milestones

- **M0 — UX Shell (React)**
  - Popup UI with bubbly cards/shadows
  - Settings panel stored via Chrome storage
- **M1 — Single Agent End-to-End**
  - /ask returns single model response
  - Display AnswerCard
- **M2 — Multi-Agent + Arbiter + Ratio**
  - Run N agents + arbiter clustering
  - Display achieved ratio + status badge
- **M3 — Reconciliation Rounds**
  - Bounded debate loop
  - Best-effort fallback
- **M4 — Polish + Store Readiness**
  - Error handling, loading micro-interactions
  - Build packaging, permissions review, privacy text

## 12. Acceptance Criteria (MVP)

- User can set N, R (0–1), max_rounds, model, and API key in the React UI.
- Asking a question returns an answer with achieved ratio and status.
- Backend uses Microsoft Agent Framework and can swap providers later.
- No infinite loops; rounds are capped; server enforces limits.
- Backend does not store or log API keys.
- UI is modern, bubbly, minimal, and performs smoothly.